{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0ebcabb-b1ba-468f-8cb3-c2903f2e652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f770f7bc-7406-4d79-9c8a-5368c8a36a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 1,\n",
       " 'is': 2,\n",
       " 'a': 3,\n",
       " 'simple': 4,\n",
       " 'example': 5,\n",
       " 'for': 6,\n",
       " 'text': 7,\n",
       " 'generation': 8,\n",
       " 'using': 9,\n",
       " 'rnn': 10,\n",
       " 'in': 11,\n",
       " 'python': 12}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example text\n",
    "data = \"This is a simple example for text generation using RNN in Python. \"\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5479f9c0-1734-4bd8-8ae9-2210e0ca4160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words = len(tokenizer.word_index) + 1\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f67b7eb9-3a95-4283-a8a9-36320e9422a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 unique characters\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Download and Prepare the Dataset ---\n",
    "path_to_file = tf.keras.utils.get_file(\n",
    "    'shakespeare.txt',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
    ")\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "# --- 2. Process the Text ---\n",
    "vocab = sorted(set(text))\n",
    "vocab = ['[UNK]'] + vocab  # Now vocab size is 66\n",
    "print(f'{len(vocab)} unique characters')\n",
    "\n",
    "chars_to_ids = {u: i for i, u in enumerate(vocab)}\n",
    "ids_to_chars = np.array(vocab)\n",
    "\n",
    "all_ids = np.array([chars_to_ids[c] for c in text])\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bdcc9448-1a00-4e0e-b12a-6fdff812b88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "source": [
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bc6c3d60-06f4-4d5d-bc97-b5f12a4da71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19 48 57 58 59  2 16 48 59 48 65 44 53 11  1 15 44 45 54 57 44  2 62 44\n",
      "  2 55 57 54 42 44 44 43  2 40 53 64  2 45 60 57 59 47 44 57  7  2 47 44\n",
      " 40 57]\n",
      "{'[UNK]': 0, '\\n': 1, ' ': 2, '!': 3, '$': 4, '&': 5, \"'\": 6, ',': 7, '-': 8, '.': 9, '3': 10, ':': 11, ';': 12, '?': 13, 'A': 14, 'B': 15, 'C': 16, 'D': 17, 'E': 18, 'F': 19, 'G': 20, 'H': 21, 'I': 22, 'J': 23, 'K': 24, 'L': 25, 'M': 26, 'N': 27, 'O': 28, 'P': 29, 'Q': 30, 'R': 31, 'S': 32, 'T': 33, 'U': 34, 'V': 35, 'W': 36, 'X': 37, 'Y': 38, 'Z': 39, 'a': 40, 'b': 41, 'c': 42, 'd': 43, 'e': 44, 'f': 45, 'g': 46, 'h': 47, 'i': 48, 'j': 49, 'k': 50, 'l': 51, 'm': 52, 'n': 53, 'o': 54, 'p': 55, 'q': 56, 'r': 57, 's': 58, 't': 59, 'u': 60, 'v': 61, 'w': 62, 'x': 63, 'y': 64, 'z': 65}\n",
      "19\n",
      "48\n",
      "57\n",
      "58\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "print(all_ids[:50])\n",
    "print(chars_to_ids)\n",
    "for id in ids_dataset.take(5):\n",
    "    print(id.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9bc91276-8d65-4f81-b8df-620868564d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=TensorSpec(shape=(101,), dtype=tf.int32, name=None)>\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Create Training Examples and Batches ---\n",
    "seq_length = 100\n",
    "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "print(sequences)\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9f737323-e7f4-4d16-9b2c-92a99f5ba28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Configure the Training Batches ---\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "# --- 5. Build The RNN Model ---\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 256\n",
    "\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "        return (x, states) if return_state else x\n",
    "\n",
    "\n",
    "model = MyModel(vocab_size=vocab_size, embedding_dim=embedding_dim, rnn_units=rnn_units)\n",
    "model.compile(optimizer='adam', loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d9d094e7-d1cb-41ab-83d9-f914590c0511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "172/172 [==============================] - 44s 252ms/step - loss: 2.0928\n",
      "Epoch 2/5\n",
      "172/172 [==============================] - 44s 255ms/step - loss: 1.8684\n",
      "Epoch 3/5\n",
      "172/172 [==============================] - 45s 256ms/step - loss: 1.7246\n",
      "Epoch 4/5\n",
      "172/172 [==============================] - 46s 266ms/step - loss: 1.6301\n",
      "Epoch 5/5\n",
      "172/172 [==============================] - 44s 254ms/step - loss: 1.5649\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Train the Model ---\n",
    "EPOCHS = 5\n",
    "history = model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b9286ac4-f876-43fc-b6bb-66570cbc9aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Generate Text ---\n",
    "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
    "chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1b2cc262-8e52-4ad8-b614-f746a7be32ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab),\n",
    "    mask_token=None,\n",
    "    oov_token=None,\n",
    "    num_oov_indices=0  # Prevents adding [UNK]\n",
    ")\n",
    "\n",
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(),\n",
    "    invert=True,\n",
    "    mask_token=None,\n",
    "    oov_token=\"[UNK]\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b63bf75f-6c93-442a-b4ef-202fd421378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # Create mask with correct vocabulary size\n",
    "        vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "        skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            values=[-float('inf')] * len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            dense_shape=[vocab_size])\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "        \n",
    "        predicted_logits, states = self.model(inputs=input_ids, states=states, return_state=True)\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits / self.temperature\n",
    "        \n",
    "        # Ensure mask matches logits shape\n",
    "        mask = tf.cast(self.prediction_mask, dtype=predicted_logits.dtype)\n",
    "        mask = tf.reshape(mask, [1, -1])  # Reshape to [1, vocab_size]\n",
    "\n",
    "        predicted_logits = predicted_logits + mask\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "        return predicted_chars, states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6490057c-9c79-451a-8fdb-07f50c9e54b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated Text ---\n",
      "ROMEO:\n",
      "Pirtation I weet behere'd:\n",
      "sorrow suthing\n",
      "'Dilign of Luck?\n",
      "Doo clood and be pine, in here--\n",
      "\n",
      "OF YORK:\n",
      "\n",
      "KING RICHARD II:\n",
      "I would thy slight, glade you the tortion asse false,\n",
      "If I dis most holt to him:\n",
      "A courtion'd itswear most somell her\n",
      "chance.\n",
      "\n",
      "SEBAWISTEBOF:\n",
      "Could they wrongs; when: when fair pleasurance, which of the scare come!\n",
      "\n",
      "JULIET:\n",
      "O, cull'd, gentlest blood honot is gively kinger\n",
      "to you to pakuing uple aboubling\n",
      "One more home! Solious lust, for thou shows, and, his woech:\n",
      "Who he te have unkid.\n",
      "Why, I see the cheeth once which love,\n",
      "The corse, the occomant,\n",
      "I'll yourse I'll not commandstick'd,\n",
      "Of he innoch accouseding say moreques me\n",
      "Do never effuries he, heart Master?\n",
      "\n",
      "ARIEL:\n",
      "No, new, by my nevery,--\n",
      "Mess'd is the Causlan, the powle to-knep,\n",
      "Antis'd anct a planted new the worther; toward\n",
      "speeds in thy spirise of for other stand, the old.\n",
      "\n",
      "ISABELIA:\n",
      "O' the backly boyes asmand tempence\n",
      "Edward so day.\n",
      "\n",
      "KICHARD II:\n",
      "He tife a'll smored that thengs, my lord,\n",
      "Will will noty, then ho\n",
      "\n",
      "Run time: 1.20s\n"
     ]
    }
   ],
   "source": [
    "# Create and test the generator\n",
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)\n",
    "\n",
    "# Generate text\n",
    "start_time = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"\\n--- Generated Text ---\")\n",
    "print(result[0].numpy().decode('utf-8'))\n",
    "print(f'\\nRun time: {end_time - start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0137663a-4510-4e7d-b880-2d15edbaac05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
